{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exploring Types of MCP Servers and Agent Memory\n",
    "\n",
    "### Welcome to Week 6 Day 3!\n",
    "\n",
    "Let's experiment with a bunch more MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üü¢ **Type 1: Local MCP Server (Everything Runs Locally)**\n",
    "\n",
    "üöÄ **What is it?**\n",
    "- A knowledge-graph based memory server.\n",
    "\n",
    "üß† **Key Features:**\n",
    "1. **Persistent Memory**: Stores entities, their observations, and relationships between them.\n",
    "2. **Knowledge Graph**: Organizes information in a graph structure for easy retrieval and reasoning.\n",
    "3. **Local Operation**: Everything runs on your machine‚Äîno cloud required!\n",
    "\n",
    "üí° **Why use it?**\n",
    "- Empowers your agent with long-term memory.\n",
    "- Enables storing and recalling facts, relationships, and context across conversations.\n",
    "\n",
    "üîó **Learn More:**  \n",
    "  üëâ https://github.com/modelcontextprotocol/servers/tree/main/src/memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='create_entities', description='Create new entities with observations and optional embeddings', inputSchema={'type': 'object', 'properties': {'entities': {'type': 'array', 'items': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'entityType': {'type': 'string'}, 'observations': {'type': 'array', 'items': {'type': 'string'}}, 'embedding': {'type': 'array', 'items': {'type': 'number'}, 'description': 'Optional vector embedding for similarity search'}}, 'required': ['name', 'entityType', 'observations']}}}, 'required': ['entities']}, annotations=None),\n",
       " Tool(name='search_nodes', description='Search for entities and their relations using text or vector similarity', inputSchema={'type': 'object', 'properties': {'query': {'oneOf': [{'type': 'string', 'description': 'Text search query'}, {'type': 'array', 'items': {'type': 'number'}, 'description': 'Vector for similarity search'}]}}, 'required': ['query']}, annotations=None),\n",
       " Tool(name='read_graph', description='Get recent entities and their relations', inputSchema={'type': 'object', 'properties': {}, 'required': []}, annotations=None),\n",
       " Tool(name='create_relations', description='Create relations between entities', inputSchema={'type': 'object', 'properties': {'relations': {'type': 'array', 'items': {'type': 'object', 'properties': {'source': {'type': 'string'}, 'target': {'type': 'string'}, 'type': {'type': 'string'}}, 'required': ['source', 'target', 'type']}}}, 'required': ['relations']}, annotations=None),\n",
       " Tool(name='delete_entity', description='Delete an entity and all its associated data (observations and relations)', inputSchema={'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'Name of the entity to delete'}}, 'required': ['name']}, annotations=None),\n",
       " Tool(name='delete_relation', description='Delete a specific relation between entities', inputSchema={'type': 'object', 'properties': {'source': {'type': 'string', 'description': 'Source entity name'}, 'target': {'type': 'string', 'description': 'Target entity name'}, 'type': {'type': 'string', 'description': 'Type of relation'}}, 'required': ['source', 'target', 'type']}, annotations=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameters required to launch the MCP memory server.\n",
    "# - \"command\": The command to execute, here \"npx\" is used to run a Node.js package.\n",
    "# - \"args\": The arguments for the command. \"-y\" auto-confirms prompts, and \"mcp-memory-libsql\" is the MCP memory server package.\n",
    "# - \"env\": Environment variables for the server process. \"LIBSQL_URL\" specifies the SQLite database file to use for persistent storage.\n",
    "params = {\n",
    "    \"command\": \"npx\",\n",
    "    \"args\": [\"-y\", \"mcp-memory-libsql\"],\n",
    "    \"env\": {\"LIBSQL_URL\": \"file:./memory/ed.db\"}\n",
    "}\n",
    "\n",
    "# Start an asynchronous context manager to launch and manage the MCP memory server process.\n",
    "# MCPServerStdio connects to the server using standard input/output pipes.\n",
    "# - params: The server launch parameters defined above.\n",
    "# - client_session_timeout_seconds: Timeout for client sessions (30 seconds here).\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    # Within the context, request the list of available MCP tools from the server.\n",
    "    # This returns a list of tool objects that the server exposes for use.\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "# Output the list of available MCP tools.\n",
    "# This will display the tools that can be used to interact with the memory server.\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You use your entity tools as a persistent memory to store and recall information about your conversations.\"\n",
    "request = \"My name's Ed. I'm an LLM engineer. I'm teaching a course about AI Agents, including the incredible MCP protocol. \\\n",
    "MCP is a protocol for connecting agents with tools, resources and prompt templates, and makes it easy to integrate AI agents with capabilities.\"\n",
    "model = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Ed! It's great that you're teaching a course about AI Agents and covering the MCP protocol. If you'd like, I can help you with creating course materials, explanations, or examples related to AI Agents and the MCP protocol. Just let me know how I can assist!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I know that you are Ed, an LLM engineer. You are also teaching a course about AI Agents. Is there anything specific you'd like to add or update about yourself?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In the previous cell, we set up an MCP memory server and used it to store some information about the user (\"My name's Ed. I'm an LLM engineer...\").\n",
    "# That cell demonstrated how to persistently store information using the MCP protocol and the memory server.\n",
    "# \n",
    "# In this cell, we are testing whether the memory server can recall information about the user that was previously stored.\n",
    "# The code launches the MCP memory server again (with the same parameters, so it uses the same persistent database).\n",
    "# It then creates an Agent with the same instructions and model as before, and connects it to the memory server.\n",
    "# The agent is asked: \"My name's Ed. What do you know about me?\".\n",
    "# The trace context (\"conversation\") is used to record the interaction for debugging or analysis.\n",
    "# The result from the agent is displayed as Markdown, which should include any information the agent has recalled about \"Ed\" from the persistent memory.\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, \"My name's Ed. What do you know about me?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2nd type of MCP server - runs locally, calls a web service\n",
    "\n",
    "### Brave Search - apologies - this will need another API key! But it's free again.\n",
    "\n",
    "https://brave.com/search/api/\n",
    "\n",
    "Set up your account, and put your key in the .env under `BRAVE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='brave_web_search', description='Performs a web search using the Brave Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. Supports pagination, content filtering, and freshness controls. Maximum 20 results per request, with offset for pagination. ', inputSchema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query (max 400 chars, 50 words)'}, 'count': {'type': 'number', 'description': 'Number of results (1-20, default 10)', 'default': 10}, 'offset': {'type': 'number', 'description': 'Pagination offset (max 9, default 0)', 'default': 0}}, 'required': ['query']}, annotations=None),\n",
       " Tool(name='brave_local_search', description=\"Searches for local businesses and places using Brave's Local Search API. Best for queries related to physical locations, businesses, restaurants, services, etc. Returns detailed information including:\\n- Business names and addresses\\n- Ratings and review counts\\n- Phone numbers and opening hours\\nUse this when the query implies 'near me' or mentions specific locations. Automatically falls back to web search if no local results are found.\", inputSchema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': \"Local search query (e.g. 'pizza near Central Park')\"}, 'count': {'type': 'number', 'description': 'Number of results (1-20, default 5)', 'default': 5}}, 'required': ['query']}, annotations=None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the environment variable dictionary with the Brave Search API key.\n",
    "# This will be passed to the MCP server process so it can authenticate requests to the Brave Search API.\n",
    "env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "\n",
    "# Define the parameters for launching the MCP server.\n",
    "# The 'env' key in the params dictionary ensures the environment variable is available to the subprocess.\n",
    "params = {\n",
    "    \"command\": \"npx\",  # Use npx to run the MCP server for Brave Search\n",
    "    \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"],  # Arguments to specify the MCP server package\n",
    "    \"env\": env  # Pass the environment variable to the server process\n",
    "}\n",
    "\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You are able to search the web for information and briefly summarize the takeaways.\"\n",
    "request = f\"Please research the latest news on Amazon stock price and briefly summarize its outlook. \\\n",
    "For context, the current date is {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of July 2025, Amazon's stock price shows a generally optimistic outlook based on the latest developments:\n",
       "\n",
       "1. **Current Price and Performance**:\n",
       "   - Amazon's stock is projected to begin July 2025 at **$220**.\n",
       "   - Forecasts suggest a potential maximum of **$255** and a minimum of **$199**, leading to an average price of **$228** for the month.\n",
       "\n",
       "2. **Long-Term Projections**:\n",
       "   - Predictive models indicate that Amazon's stock could see an increase from **$447** to **$563** by 2032, marking a growth potential of around **+26%** over the next few years.\n",
       "\n",
       "3. **Recent Analyst Ratings**:\n",
       "   - Truist recently raised its price target for Amazon from **$226** to **$250**, maintaining a \"Buy\" rating, reflecting positive sentiment among analysts.\n",
       "\n",
       "4. **Market Capitalization**:\n",
       "   - Amazon's market capitalization stands at approximately **$2.33 trillion**, with a slight increase of **1.37%** in the past week.\n",
       "\n",
       "5. **Upcoming Earnings Report**:\n",
       "   - Investors are awaiting the next earnings report, which is scheduled for **July 31, 2025**, a pivotal event that may influence stock performance.\n",
       "\n",
       "Overall, the outlook for Amazon's stock appears favorable, supported by positive analyst ratings and market expectations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As usual, check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Third Type: Running MCP Servers Remotely\n",
    "\n",
    "### What is a \"Remote MCP Server\"? ü§î\n",
    "- Also called **hosted MCP server** or **managed MCP server**\n",
    "- These are MCP servers that run on someone else's infrastructure, not your local machine.\n",
    "\n",
    "### Availability & Discovery üîç\n",
    "- Finding a public or managed remote MCP server is **rare**.\n",
    "- There is **no standard directory** or discovery mechanism for public MCP servers.\n",
    "\n",
    "### Who Offers Remote MCP Servers? üè¢\n",
    "- **Anthropic**: Lists some remote MCP servers, but these are for **paid, business users** only.\n",
    "  - üìÑ [Anthropic Remote MCP Servers Documentation](https://docs.anthropic.com/en/docs/agents-and-tools/remote-mcp-servers)\n",
    "\n",
    "- **Cloudflare**: Provides tooling to **create and deploy your own** remote MCP servers.\n",
    "  - ‚öôÔ∏è [Cloudflare Remote MCP Server Guide](https://developers.cloudflare.com/agents/guides/remote-mcp-server/)\n",
    "  - Note: This is not a common practice yet.\n",
    "\n",
    "### Summary üìù\n",
    "- Remote MCP servers are possible, but **not common** or widely available for general use.\n",
    "- Most users will run MCP servers **locally** or within their own cloud infrastructure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And back to the 2nd type: the Polygon.io MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 90px; height: 90px; vertical-align: middle; font-size: 80px; text-align: center;\">\n",
    "            üõëüõë<br>\n",
    "            <span style=\"font-size: 40px;\">üö¶</span>\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">PLEASE READ!!-</h2>\n",
    "            <span style=\"color:#ff7800;\">This service for financial market data has both a FREE plan and a PAID plan, and we can use either depending on your appetite.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW SECTION: Introducing polygon.io\n",
    "\n",
    "Polygon.io is a hugely popular financial data provider. It has a free plan and a paid plan. And it also has an MCP Server!\n",
    "\n",
    "First, read up on polygon.io on their excellent website, including looking at their pricing:\n",
    "\n",
    "https://polygon.io\n",
    "\n",
    "### Polygon.io Part 1: Polygon.io free service (the paid will be totally optional, of course!)\n",
    "\n",
    "1. Please sign up for polygon.io (top right)  \n",
    "2. Once signed in, please select \"Keys\" in the left hand navigation\n",
    "3. Press the blue \"New Key\" button\n",
    "4. Copy the key name\n",
    "5. Edit your .env file and add the row:\n",
    "\n",
    "`POLYGON_API_KEY=xxxx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "if not polygon_api_key:\n",
    "    print(\"POLYGON_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreviousCloseAgg(ticker='AAPL', close=211.14, high=211.33, low=207.22, open=209.53, timestamp=1752091200000, volume=48749367.0, vwap=209.5626)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polygon import RESTClient\n",
    "client = RESTClient(polygon_api_key)\n",
    "client.get_previous_close_agg(\"AAPL\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped into a python module that caches end of day prices\n",
    "\n",
    "I've made a python module `market.py` that uses this API to look up share prices.\n",
    "\n",
    "But the free API is quite heavily rate limited - so I've been a bit sneaky; when you ask for a share price, this function retrieves the entire end-of-day equity market, and caches it in our database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211.14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from market import get_share_price\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211.14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no rate limiting concerns!\n",
    "\n",
    "for i in range(1000):\n",
    "    get_share_price(\"AAPL\")\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And I've made this into an MCP Server\n",
    "\n",
    "Just as we did with accounts.py; see `market_server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='lookup_share_price', description='This tool provides the current price of the given stock symbol.\\n\\n    Args:\\n        symbol: the symbol of the stock\\n    ', inputSchema={'properties': {'symbol': {'title': 'Symbol', 'type': 'string'}}, 'required': ['symbol'], 'title': 'lookup_share_priceArguments', 'type': 'object'}, annotations=None)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]}\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try it out!\n",
    "\n",
    "Hopefully gpt-4o-mini is smart enough to know that the symbol for Apple is AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current share price of Apple (AAPL) is $211.14."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple?\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon.io Part 2: Paid Plan - Totally Optional!\n",
    "\n",
    "If you are interested, you can subscribe to the monthly plan to get more up to date market data, and unlimited API calls.\n",
    "\n",
    "If you do wish to do this, then it also makes sense to use the full MCP server that Polygon.io has released, to take advantage of all their functionality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"command\": \"uvx\",\n",
    "          \"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@v0.1.0\", \"mcp_polygon\"],\n",
    "          \"env\": {\"POLYGON_API_KEY\": polygon_api_key}\n",
    "          }\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow that's a lot of tools!\n",
    "\n",
    "Let's try them out - hopefully the sheer number of tools doesn't overwhelm gpt-4o-mini!\n",
    "\n",
    "With the $29 monthly plan, we don't have access to some of the APIs, so I've needed to specify which APIs can be called.\n",
    "\n",
    "If you've splashed out on a bigger plan, feel free to remove my extra constraint.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple? Use your get_snapshot_ticker tool to get the latest price.\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your .env file\n",
    "\n",
    "If you do decide to have a paid plan, please add this to your .env file to indicate:\n",
    "\n",
    "`POLYGON_PLAN=paid`\n",
    "\n",
    "And if you decide to go all the way for the realtime API, then please do:\n",
    "\n",
    "`POLYGON_PLAN=realtime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "if is_paid_polygon:\n",
    "    print(\"You've chosen to subscribe to the paid Polygon plan, so the code will look at prices on a 15 min delay\")\n",
    "elif is_realtime_polygon:\n",
    "    print(\"Wowzer - you've chosen to subscribe to the realtime Polygon plan, so the code will look at realtime prices\")\n",
    "else:\n",
    "    print(\"According to your .env file, you've chosen to subscribe to the free Polygon plan, so the code will look at EOD prices\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
